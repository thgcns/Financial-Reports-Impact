{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bibliotecas\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import get_close_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis\n",
    "\n",
    "start_y = 2011\n",
    "final_y = 2022\n",
    "codecvm = '019348'\n",
    "#arquivo com data da publicação de relatórios\n",
    "event_dates_file =  'c:\\\\Users\\\\thgcn\\\\OneDrive\\\\Academico\\\\Financial-Reports-Impact\\\\data\\\\itr_date_itau.csv'\n",
    "#arquivo com preços históricos\n",
    "itau_file = 'c:\\\\Users\\\\thgcn\\\\OneDrive\\\\Academico\\\\Financial-Reports-Impact\\\\data\\\\\\historical_data\\\\ITUB4.SA.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funções \n",
    "\n",
    "# 1- captura da data de publicação\n",
    "\n",
    "def busca_itr(ano):\n",
    "    \"\"\"\n",
    "    Verifica se o diretório informado pelo usuário é válido.\n",
    "\n",
    "    Returns:\n",
    "        str: O caminho absoluto do diretório válido.\n",
    "\n",
    "    Example:\n",
    "        >>> verificar_diretorio()\n",
    "        Digite o caminho do diretório: /caminho/do/diretorio\n",
    "        Diretório raiz para armazenamento dos documentos: /caminho/do/diretorio\n",
    "        '/caminho/do/diretorio'\n",
    "\n",
    "    \"\"\"\n",
    "    url = 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/itr_cia_aberta_%d.zip' % ano\n",
    "    file = 'ipe_cia_aberta_%d.zip' % ano\n",
    "    r = requests.get(url)\n",
    "    zf = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    file = zf.namelist()\n",
    "    zf = zf.open(file[0])\n",
    "    lines = zf.readlines()\n",
    "    lines = [i.strip().decode('ISO-8859-1') for i in lines]\n",
    "    lines = [i.split(';') for i in lines]\n",
    "    qtl = len(lines)\n",
    "    return lines\n",
    "\n",
    "def save_cvm_dates_combined(start_y, final_y, codecvm, event_dates_file):\n",
    "    combined_data = pd.DataFrame()  # DataFrame vazio para acumular os resultados\n",
    "    \n",
    "    # Loop para chamar a função para os anos de start_y a final_y\n",
    "    for year in range(start_y, final_y + 1):\n",
    "        # Suponha que 'busca_itr(year)' seja uma função que retorna os dados para o ano especificado\n",
    "        data = busca_itr(year)\n",
    "        \n",
    "        # Criar um DataFrame a partir dos dados\n",
    "        df = pd.DataFrame(data[1:], columns=data[0])\n",
    "        \n",
    "        # Filtrar os dados para o CD_CVM específico (codecvm)\n",
    "        filtered_data = df.loc[df['CD_CVM'] == codecvm]\n",
    "        \n",
    "        # Selecionar apenas as colunas CD_CVM e DT_RECEB\n",
    "        filtered_data = filtered_data[['CD_CVM', 'DT_RECEB']]\n",
    "        \n",
    "        # Adicionar os dados filtrados ao DataFrame acumulado\n",
    "        combined_data = pd.concat([combined_data, filtered_data], ignore_index=True)\n",
    "    \n",
    "    # Salvar os dados acumulados como um único arquivo CSV\n",
    "    combined_data.to_csv(event_dates_file, index=False)\n",
    "    print(f'Dados combinados (CD_CVM e DT_RECEB) salvos em {event_dates_file}')    \n",
    "    combined_data = pd.DataFrame()  # DataFrame vazio para acumular os resultados\n",
    "    \n",
    "def process_itau_data(itau_file, event_dates_file, codecvm):\n",
    "    # Carregar dados do arquivo ITUB4.SA.csv\n",
    "    itau_data = pd.read_csv(itau_file)\n",
    "    itau_data['Date'] = pd.to_datetime(itau_data['Date'])  # Converter a coluna Date para o tipo datetime\n",
    "\n",
    "    # Calcular o retorno diário em escala logarítmica\n",
    "    itau_data['Return'] = np.log(itau_data['Close'] / itau_data['Close'].shift(1))\n",
    "\n",
    "    # Carregar datas de eventos do arquivo itr_date_itau.csv\n",
    "    event_dates = pd.read_csv(event_dates_file)\n",
    "    event_dates['DT_RECEB'] = pd.to_datetime(event_dates['DT_RECEB'])  # Converter a coluna Date para o tipo datetime\n",
    "\n",
    "    # Definir as datas de eventos como um conjunto para busca eficiente\n",
    "    event_set = set(event_dates['DT_RECEB'])\n",
    "\n",
    "    # Determinar se cada data é um evento (1) ou não (0)\n",
    "    itau_data['event'] = itau_data['Date'].isin(event_set).astype(int)\n",
    "\n",
    "    # Receber o codcvm via parâmetro de entrada da função\n",
    "    itau_data['CD_CVM'] = codecvm\n",
    "\n",
    "    # Selecionar as colunas relevantes para o DataFrame final\n",
    "    final_data = itau_data[['CD_CVM', 'Date', 'Return', 'event']]\n",
    "    \n",
    "    return final_data \n",
    "\n",
    "def analyze_data_quality(final_data):\n",
    "    # Identificar quantos \"COD_CVM\" distintos existem na base e exibir os valores\n",
    "    unique_cod_cvm = final_data['CD_CVM'].unique()\n",
    "    num_unique_cod_cvm = len(unique_cod_cvm)\n",
    "    print(f\"Existem {num_unique_cod_cvm} COD_CVM distintos na base:\")\n",
    "    print(unique_cod_cvm)\n",
    "    \n",
    "    # Identificar quantas datas iguais existem em \"Date\" e exibir os valores\n",
    "    date_counts = final_data['Date'].value_counts()\n",
    "    duplicate_dates = date_counts[date_counts > 1]\n",
    "    print(f\"\\nExistem {len(duplicate_dates)} datas repetidas na base:\")\n",
    "    print(duplicate_dates)\n",
    "    \n",
    "    # Contar quantos eventos iguais a 0 e 1 existem na base\n",
    "    event_0_count = (final_data['event'] == 0).sum()\n",
    "    event_1_count = (final_data['event'] == 1).sum()\n",
    "    print(f\"\\nContagem de eventos:\")\n",
    "    print(f\"Eventos iguais a 0: {event_0_count}\")\n",
    "    print(f\"Eventos iguais a 1: {event_1_count}\")\n",
    "    \n",
    "    # Contar quantas vezes o evento = 1 em um intervalo de 1 ano e exibir as datas\n",
    "    final_data['Year'] = final_data['Date'].dt.year\n",
    "    events_by_year = final_data[final_data['event'] == 1].groupby('Year')['Date'].apply(list).reset_index()\n",
    "    for _, row in events_by_year.iterrows():\n",
    "        year = row['Year']\n",
    "        event_dates = row['Date']\n",
    "        print(f\"\\n{year}: {len(event_dates)} eventos\")\n",
    "        for date in event_dates:\n",
    "            print(date.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    # Identificar quais colunas contêm valores NaN e quantas vezes\n",
    "    nan_counts = final_data.isna().sum()\n",
    "    columns_with_nan = nan_counts[nan_counts > 0]\n",
    "    print(f\"\\nColunas com valores NaN e a quantidade de NaNs:\")\n",
    "    print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados combinados (CD_CVM e DT_RECEB) salvos em c:\\Users\\thgcn\\OneDrive\\Academico\\Financial-Reports-Impact\\data\\itr_date_itau.csv\n"
     ]
    }
   ],
   "source": [
    "#chamada da função\n",
    "\n",
    "save_cvm_dates_combined(start_y, final_y, codecvm, event_dates_file)\n",
    "final_data = process_itau_data(itau_file, event_dates_file, codecvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existem 1 COD_CVM distintos na base:\n",
      "['019348']\n",
      "\n",
      "Existem 0 datas repetidas na base:\n",
      "Series([], Name: Date, dtype: int64)\n",
      "\n",
      "Contagem de eventos:\n",
      "Eventos iguais a 0: 3186\n",
      "Eventos iguais a 1: 39\n",
      "\n",
      "2011: 4 eventos\n",
      "2011-05-03\n",
      "2011-08-02\n",
      "2011-08-03\n",
      "2011-11-01\n",
      "\n",
      "2012: 4 eventos\n",
      "2012-04-24\n",
      "2012-07-24\n",
      "2012-10-23\n",
      "2012-10-30\n",
      "\n",
      "2013: 3 eventos\n",
      "2013-04-30\n",
      "2013-07-30\n",
      "2013-10-29\n",
      "\n",
      "2014: 3 eventos\n",
      "2014-04-29\n",
      "2014-08-05\n",
      "2014-11-04\n",
      "\n",
      "2015: 3 eventos\n",
      "2015-05-05\n",
      "2015-08-04\n",
      "2015-11-03\n",
      "\n",
      "2016: 3 eventos\n",
      "2016-05-03\n",
      "2016-08-02\n",
      "2016-10-31\n",
      "\n",
      "2017: 4 eventos\n",
      "2017-05-03\n",
      "2017-07-31\n",
      "2017-08-11\n",
      "2017-10-30\n",
      "\n",
      "2018: 2 eventos\n",
      "2018-07-30\n",
      "2018-10-29\n",
      "\n",
      "2019: 4 eventos\n",
      "2019-05-02\n",
      "2019-07-29\n",
      "2019-11-04\n",
      "2019-11-25\n",
      "\n",
      "2020: 3 eventos\n",
      "2020-05-04\n",
      "2020-08-03\n",
      "2020-11-03\n",
      "\n",
      "2021: 3 eventos\n",
      "2021-05-03\n",
      "2021-08-02\n",
      "2021-11-03\n",
      "\n",
      "2022: 3 eventos\n",
      "2022-05-09\n",
      "2022-08-08\n",
      "2022-11-10\n",
      "\n",
      "Colunas com valores NaN e a quantidade de NaNs:\n",
      "Return    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Chamada da função para analisar a qualidade dos dados\n",
    "analyze_data_quality(final_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
