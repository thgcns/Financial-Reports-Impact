{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bibliotecas\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import get_close_matches\n",
    "import unidecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis\n",
    "\n",
    "start_y = 2011\n",
    "final_y = 2022\n",
    "codecvm = '19348'\n",
    "#arquivo com data da publicação de relatórios\n",
    "event_dates_file =  'c:\\\\Users\\\\thgcn\\\\OneDrive\\\\Academico\\\\Financial-Reports-Impact\\\\data\\\\itr_date_itau.csv'\n",
    "#arquivo com preços históricos\n",
    "itau_file = 'c:\\\\Users\\\\thgcn\\\\OneDrive\\\\Academico\\\\Financial-Reports-Impact\\\\data\\\\\\historical_data\\\\ITUB4.SA.csv'\n",
    "#arquivo final\n",
    "output_file = 'c:\\\\Users\\\\thgcn\\\\OneDrive\\\\Academico\\\\Financial-Reports-Impact\\\\data\\\\final_data.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funções (contendo visao de janelas)\n",
    "\n",
    "def busca_date_pub(ano, codecvm):\n",
    "    \"\"\"\n",
    "    Busca dados de publicação no site da CVM para o ano e código CVM especificados.\n",
    "\n",
    "    Args:\n",
    "        ano (int): O ano dos dados.\n",
    "        codecvm (str): O código CVM da empresa.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de tuplas contendo os campos Assunto e Data_Entrega para o código CVM especificado.\n",
    "\n",
    "    Example:\n",
    "        >>> busca_date_pub(2023, '019348')\n",
    "        [('Informações consolidadas dos exercícios', '2023-05-15'), ...]\n",
    "    \"\"\"\n",
    "    url = 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/IPE/DADOS/ipe_cia_aberta_%d.zip' % ano\n",
    "    r = requests.get(url)\n",
    "    zf = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    file = zf.namelist()\n",
    "    zf = zf.open(file[0])\n",
    "    lines = zf.readlines()\n",
    "    lines = [i.strip().decode('ISO-8859-1') for i in lines]\n",
    "    lines = [i.split(';') for i in lines]\n",
    "\n",
    "    # Header mapping to find indexes of relevant columns\n",
    "    header = lines[0]\n",
    "    idx_codigo_cvm = header.index('Codigo_CVM')\n",
    "    idx_assunto = header.index('Assunto')\n",
    "    idx_data_entrega = header.index('Data_Entrega')\n",
    "\n",
    "    # Strings de busca normalizadas para evitar problemas com acentos e maiúsculas/minúsculas\n",
    "    busca1 = unidecode.unidecode(\"Informações consolidadas dos exercícios\").lower()\n",
    "    busca2 = unidecode.unidecode(\"Informações sobre o resultado\").lower()\n",
    "\n",
    "    result = []\n",
    "    for line in lines[1:]:\n",
    "        if line[idx_codigo_cvm] == codecvm:\n",
    "            assunto_normalizado = unidecode.unidecode(line[idx_assunto]).lower()\n",
    "            if busca1 in assunto_normalizado or busca2 in assunto_normalizado:\n",
    "                result.append((line[idx_codigo_cvm], line[idx_assunto], line[idx_data_entrega]))\n",
    "\n",
    "    # Convertendo o resultado em um DataFrame\n",
    "    df_result = pd.DataFrame(result, columns=['Codigo_CVM', 'Assunto', 'Data_Entrega'])\n",
    "\n",
    "    return df_result\n",
    "\n",
    "def save_cvm_dates_combined(start_y, final_y, codecvm, event_dates_file):\n",
    "    combined_data = pd.DataFrame()  # DataFrame vazio para acumular os resultados\n",
    "    \n",
    "    # Loop para chamar a função para os anos de start_y a final_y\n",
    "    for year in range(start_y, final_y + 1):\n",
    "        # Obter os dados para o ano especificado\n",
    "        df = busca_date_pub(year, codecvm)\n",
    "        \n",
    "        # Adicionar os dados ao DataFrame acumulado\n",
    "        combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
    "    \n",
    "    # Salvar os dados acumulados como um único arquivo CSV\n",
    "    combined_data.to_csv(event_dates_file, index=False)\n",
    "    print(f'Dados combinados (Codigo_CVM, Assunto e Data_Entrega) salvos em {event_dates_file}')    \n",
    "\n",
    "def process_itau_data(itau_file, event_dates_file, codecvm):\n",
    "    # Carregar dados do arquivo ITUB4.SA.csv\n",
    "    itau_data = pd.read_csv(itau_file)\n",
    "    itau_data['Date'] = pd.to_datetime(itau_data['Date'])  # Converter a coluna Date para o tipo datetime\n",
    "\n",
    "    # Carregar datas de eventos do arquivo itr_date_itau.csv\n",
    "    event_dates = pd.read_csv(event_dates_file)\n",
    "    event_dates['Data_Entrega'] = pd.to_datetime(event_dates['Data_Entrega'])  # Converter a coluna Data_Entrega para o tipo datetime\n",
    "\n",
    "    # Definir as datas de eventos como um conjunto para busca eficiente\n",
    "    event_set = set(event_dates['Data_Entrega'])\n",
    "\n",
    "    # Determinar se cada data é um evento (1) ou não (0)\n",
    "    itau_data['event'] = itau_data['Date'].isin(event_set).astype(int)\n",
    "\n",
    "    # Receber o codcvm via parâmetro de entrada da função\n",
    "    itau_data['CD_CVM'] = codecvm\n",
    "    # Calcular o retorno diário em escala logarítmica\n",
    "    itau_data['Return'] = np.log(itau_data['Close'] / itau_data['Close'].shift(1))\n",
    "\n",
    "    # Calcular o retorno semanal em escala logarítmica\n",
    "    #itau_data['week_return'] = np.log(itau_data['Close'] / itau_data['Close'].shift(5))\n",
    "\n",
    "    # Calcular o retorno mensal em escala logarítmica\n",
    "    #itau_data['month_return'] = np.log(itau_data['Close'] / itau_data['Close'].shift(22))\n",
    "       \n",
    "    # Selecionar as colunas relevantes para o DataFrame final\n",
    "    final_data = itau_data[['CD_CVM', 'Date', 'Return', 'event']]\n",
    "    \n",
    "    return final_data\n",
    "\n",
    "def analyze_data_quality(final_data):\n",
    "    # Identificar quantos \"COD_CVM\" distintos existem na base e exibir os valores\n",
    "    unique_cod_cvm = final_data['CD_CVM'].unique()\n",
    "    num_unique_cod_cvm = len(unique_cod_cvm)\n",
    "    print(f\"Existem {num_unique_cod_cvm} COD_CVM distintos na base:\")\n",
    "    print(unique_cod_cvm)\n",
    "    \n",
    "    # Identificar quantas datas iguais existem em \"Date\" e exibir os valores\n",
    "    final_data['Date'] = pd.to_datetime(final_data['Date'], errors='coerce')\n",
    "    date_counts = final_data['Date'].value_counts()\n",
    "    duplicate_dates = date_counts[date_counts > 1]\n",
    "    print(f\"\\nExistem {len(duplicate_dates)} datas repetidas na base:\")\n",
    "    print(duplicate_dates)\n",
    "    \n",
    "    # Contar quantos eventos iguais a 0 e 1 existem na base\n",
    "    event_0_count = (final_data['event'] == 0).sum()\n",
    "    event_1_count = (final_data['event'] == 1).sum()\n",
    "    print(f\"\\nContagem de eventos:\")\n",
    "    print(f\"Eventos iguais a 0: {event_0_count}\")\n",
    "    print(f\"Eventos iguais a 1: {event_1_count}\")\n",
    "    \n",
    "    # Identificar quais colunas contêm valores NaN e quantas vezes\n",
    "    nan_counts = final_data.isna().sum()\n",
    "    columns_with_nan = nan_counts[nan_counts > 0]\n",
    "    print(f\"\\nColunas com valores NaN e a quantidade de NaNs:\")\n",
    "    print(columns_with_nan)\n",
    "    \n",
    "    # Contar eventos (event=1) em uma janela de um ano e exibir as datas\n",
    "    final_data['Year'] = final_data['Date'].dt.year\n",
    "    event_dates_by_year = final_data[final_data['event'] == 1].groupby('Year')['Date'].apply(list)\n",
    "    \n",
    "    print(\"\\nPublicações anuais (event=1):\")\n",
    "    for year, dates in event_dates_by_year.items():\n",
    "        print(f\"{year}: {len(dates)} publicações\")\n",
    "        for date in dates:\n",
    "            print(date.strftime('%Y-%m-%d'))\n",
    "        print(\"------------\")\n",
    "        \n",
    "        \n",
    "def add_and_reorder(df, cd_cvm, date, ret, event, year):\n",
    "    \"\"\"\n",
    "    Adiciona uma nova linha ao DataFrame e reordena por data em ordem decrescente.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame original.\n",
    "        cd_cvm (str): Valor para a coluna 'CD_CVM'.\n",
    "        date (str): Valor para a coluna 'Date' no formato 'YYYY-MM-DD'.\n",
    "        ret (str): Valor para a coluna 'Return'.\n",
    "        event (int): Valor para a coluna 'event'.\n",
    "        year (int): Valor para a coluna 'Year'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame atualizado com a nova linha e reordenado por data.\n",
    "    \"\"\"\n",
    "    # Criar uma nova linha como um DataFrame\n",
    "    new_row = pd.DataFrame({\n",
    "        'CD_CVM': [cd_cvm],\n",
    "        'Date': [pd.to_datetime(date)],\n",
    "        'Return': [float(ret) if ret else None],\n",
    "        'event': [int(event)],\n",
    "        'Year': [int(year)]\n",
    "    })\n",
    "\n",
    "    # Adicionar a nova linha ao DataFrame original\n",
    "    updated_df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "    # Reordenar o DataFrame por data em ordem decrescente\n",
    "    updated_df = updated_df.sort_values(by='Date', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return updated_df\n",
    "\n",
    "def set_event(df, date):\n",
    "    \"\"\"\n",
    "    Altera o valor da coluna 'event' para 1 para uma data específica.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame original.\n",
    "        date (str): Data no formato 'YYYY-MM-DD' para a qual o valor de 'event' deve ser alterado.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame atualizado com o valor de 'event' alterado para 1 na data especificada.\n",
    "    \"\"\"\n",
    "    # Converter a coluna 'Date' para o tipo datetime, caso ainda não esteja\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Alterar o valor da coluna 'event' para 1 na data especificada\n",
    "    df.loc[df['Date'] == pd.to_datetime(date), 'event'] = 1\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desconsiderar (NÃO EXECUTE ESTA CELULA)\n",
    "# funções\n",
    "\n",
    "def busca_date_pub(ano, codecvm):\n",
    "    \"\"\"\n",
    "    Busca dados de publicação no site da CVM para o ano e código CVM especificados.\n",
    "\n",
    "    Args:\n",
    "        ano (int): O ano dos dados.\n",
    "        codecvm (str): O código CVM da empresa.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de tuplas contendo os campos Assunto e Data_Entrega para o código CVM especificado.\n",
    "\n",
    "    Example:\n",
    "        >>> busca_date_pub(2023, '019348')\n",
    "        [('Informações consolidadas dos exercícios', '2023-05-15'), ...]\n",
    "    \"\"\"\n",
    "    url = 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/IPE/DADOS/ipe_cia_aberta_%d.zip' % ano\n",
    "    r = requests.get(url)\n",
    "    zf = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    file = zf.namelist()\n",
    "    zf = zf.open(file[0])\n",
    "    lines = zf.readlines()\n",
    "    lines = [i.strip().decode('ISO-8859-1') for i in lines]\n",
    "    lines = [i.split(';') for i in lines]\n",
    "\n",
    "    # Header mapping to find indexes of relevant columns\n",
    "    header = lines[0]\n",
    "    idx_codigo_cvm = header.index('Codigo_CVM')\n",
    "    idx_assunto = header.index('Assunto')\n",
    "    idx_data_entrega = header.index('Data_Entrega')\n",
    "\n",
    "    # Strings de busca normalizadas para evitar problemas com acentos e maiúsculas/minúsculas\n",
    "    busca1 = unidecode.unidecode(\"Informações consolidadas dos exercícios\").lower()\n",
    "    busca2 = unidecode.unidecode(\"Informações sobre o resultado\").lower()\n",
    "\n",
    "    result = []\n",
    "    for line in lines[1:]:\n",
    "        if line[idx_codigo_cvm] == codecvm:\n",
    "            assunto_normalizado = unidecode.unidecode(line[idx_assunto]).lower()\n",
    "            if busca1 in assunto_normalizado or busca2 in assunto_normalizado:\n",
    "                result.append((line[idx_codigo_cvm], line[idx_assunto], line[idx_data_entrega]))\n",
    "\n",
    "    # Convertendo o resultado em um DataFrame\n",
    "    df_result = pd.DataFrame(result, columns=['Codigo_CVM', 'Assunto', 'Data_Entrega'])\n",
    "\n",
    "    return df_result\n",
    "\n",
    "def save_cvm_dates_combined(start_y, final_y, codecvm, event_dates_file):\n",
    "    combined_data = pd.DataFrame()  # DataFrame vazio para acumular os resultados\n",
    "    \n",
    "    # Loop para chamar a função para os anos de start_y a final_y\n",
    "    for year in range(start_y, final_y + 1):\n",
    "        # Obter os dados para o ano especificado\n",
    "        df = busca_date_pub(year, codecvm)\n",
    "        \n",
    "        # Adicionar os dados ao DataFrame acumulado\n",
    "        combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
    "    \n",
    "    # Salvar os dados acumulados como um único arquivo CSV\n",
    "    combined_data.to_csv(event_dates_file, index=False)\n",
    "    print(f'Dados combinados (Codigo_CVM, Assunto e Data_Entrega) salvos em {event_dates_file}')    \n",
    "\n",
    "def process_itau_data(itau_file, event_dates_file, codecvm):\n",
    "    # Carregar dados do arquivo ITUB4.SA.csv\n",
    "    itau_data = pd.read_csv(itau_file)\n",
    "    itau_data['Date'] = pd.to_datetime(itau_data['Date'])  # Converter a coluna Date para o tipo datetime\n",
    "\n",
    "    # Calcular o retorno diário em escala logarítmica\n",
    "    itau_data['Return'] = np.log(itau_data['Close'] / itau_data['Close'].shift(1))\n",
    "\n",
    "    # Carregar datas de eventos do arquivo itr_date_itau.csv\n",
    "    event_dates = pd.read_csv(event_dates_file)\n",
    "    event_dates['Data_Entrega'] = pd.to_datetime(event_dates['Data_Entrega'])  # Converter a coluna Data_Entrega para o tipo datetime\n",
    "\n",
    "    # Definir as datas de eventos como um conjunto para busca eficiente\n",
    "    event_set = set(event_dates['Data_Entrega'])\n",
    "\n",
    "    # Determinar se cada data é um evento (1) ou não (0)\n",
    "    itau_data['event'] = itau_data['Date'].isin(event_set).astype(int)\n",
    "\n",
    "    # Receber o codcvm via parâmetro de entrada da função\n",
    "    itau_data['CD_CVM'] = codecvm\n",
    "\n",
    "    # Selecionar as colunas relevantes para o DataFrame final\n",
    "    final_data = itau_data[['CD_CVM', 'Date', 'Return', 'event']]\n",
    "    \n",
    "    return final_data\n",
    "\n",
    "def analyze_data_quality(final_data):\n",
    "    # Identificar quantos \"COD_CVM\" distintos existem na base e exibir os valores\n",
    "    unique_cod_cvm = final_data['CD_CVM'].unique()\n",
    "    num_unique_cod_cvm = len(unique_cod_cvm)\n",
    "    print(f\"Existem {num_unique_cod_cvm} COD_CVM distintos na base:\")\n",
    "    print(unique_cod_cvm)\n",
    "    \n",
    "    # Identificar quantas datas iguais existem em \"Date\" e exibir os valores\n",
    "    date_counts = final_data['Date'].value_counts()\n",
    "    duplicate_dates = date_counts[date_counts > 1]\n",
    "    print(f\"\\nExistem {len(duplicate_dates)} datas repetidas na base:\")\n",
    "    print(duplicate_dates)\n",
    "    \n",
    "    # Contar quantos eventos iguais a 0 e 1 existem na base\n",
    "    event_0_count = (final_data['event'] == 0).sum()\n",
    "    event_1_count = (final_data['event'] == 1).sum()\n",
    "    print(f\"\\nContagem de eventos:\")\n",
    "    print(f\"Eventos iguais a 0: {event_0_count}\")\n",
    "    print(f\"Eventos iguais a 1: {event_1_count}\")\n",
    "    \n",
    "    # Identificar quais colunas contêm valores NaN e quantas vezes\n",
    "    nan_counts = final_data.isna().sum()\n",
    "    columns_with_nan = nan_counts[nan_counts > 0]\n",
    "    print(f\"\\nColunas com valores NaN e a quantidade de NaNs:\")\n",
    "    print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados combinados (Codigo_CVM, Assunto e Data_Entrega) salvos em c:\\Users\\thgcn\\OneDrive\\Academico\\Financial-Reports-Impact\\data\\itr_date_itau.csv\n",
      "Existem 1 COD_CVM distintos na base:\n",
      "['19348']\n",
      "\n",
      "Existem 0 datas repetidas na base:\n",
      "Series([], Name: Date, dtype: int64)\n",
      "\n",
      "Contagem de eventos:\n",
      "Eventos iguais a 0: 3177\n",
      "Eventos iguais a 1: 48\n",
      "\n",
      "Colunas com valores NaN e a quantidade de NaNs:\n",
      "Return    1\n",
      "dtype: int64\n",
      "\n",
      "Publicações anuais (event=1):\n",
      "2011: 4 publicações\n",
      "2011-02-22\n",
      "2011-05-03\n",
      "2011-08-02\n",
      "2011-11-01\n",
      "------------\n",
      "2012: 4 publicações\n",
      "2012-02-07\n",
      "2012-04-24\n",
      "2012-07-24\n",
      "2012-10-23\n",
      "------------\n",
      "2013: 4 publicações\n",
      "2013-02-05\n",
      "2013-04-30\n",
      "2013-07-30\n",
      "2013-10-29\n",
      "------------\n",
      "2014: 4 publicações\n",
      "2014-02-04\n",
      "2014-04-29\n",
      "2014-08-05\n",
      "2014-11-04\n",
      "------------\n",
      "2015: 4 publicações\n",
      "2015-02-03\n",
      "2015-05-05\n",
      "2015-08-04\n",
      "2015-11-03\n",
      "------------\n",
      "2016: 4 publicações\n",
      "2016-02-02\n",
      "2016-05-03\n",
      "2016-08-02\n",
      "2016-10-31\n",
      "------------\n",
      "2017: 4 publicações\n",
      "2017-02-07\n",
      "2017-05-03\n",
      "2017-07-31\n",
      "2017-10-30\n",
      "------------\n",
      "2018: 4 publicações\n",
      "2018-02-05\n",
      "2018-04-30\n",
      "2018-07-30\n",
      "2018-10-29\n",
      "------------\n",
      "2019: 4 publicações\n",
      "2019-02-04\n",
      "2019-05-02\n",
      "2019-07-29\n",
      "2019-11-04\n",
      "------------\n",
      "2020: 4 publicações\n",
      "2020-02-10\n",
      "2020-05-04\n",
      "2020-08-04\n",
      "2020-11-04\n",
      "------------\n",
      "2021: 4 publicações\n",
      "2021-02-02\n",
      "2021-05-04\n",
      "2021-08-03\n",
      "2021-11-04\n",
      "------------\n",
      "2022: 4 publicações\n",
      "2022-02-11\n",
      "2022-05-09\n",
      "2022-08-09\n",
      "2022-11-11\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "#chamada da função\n",
    "save_cvm_dates_combined(start_y, final_y, codecvm, event_dates_file)\n",
    "final_data = process_itau_data(itau_file, event_dates_file, codecvm)\n",
    "# Correção para itau\n",
    "set_event(final_data, \"2018-04-30\")\n",
    "set_event(final_data, \"2021-11-04\")\n",
    "set_event(final_data, \"2022-11-11\")\n",
    "#qualidade\n",
    "analyze_data_quality(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def return_week(final_data):\n",
    "    # Garantir que a coluna 'Date' seja do tipo datetime\n",
    "    final_data['Date'] = pd.to_datetime(final_data['Date'])\n",
    "\n",
    "    # Filtrar os eventos positivos\n",
    "    event_data = final_data[final_data['event'] == 1].copy()\n",
    "\n",
    "    # Inicializar a coluna 'Return_week' com NaN\n",
    "    final_data['Return_week'] = np.nan\n",
    "\n",
    "    # Iterar sobre os índices dos eventos positivos\n",
    "    for idx in event_data.index:\n",
    "        if idx + 5 < len(final_data):\n",
    "            # Calcular o retorno semanal\n",
    "            final_data.loc[idx, 'Return_week'] = np.log(final_data.loc[idx + 5, 'Close'] / final_data.loc[idx, 'Close'])\n",
    "\n",
    "    # Selecionar as colunas relevantes para o DataFrame final\n",
    "    final_data = final_data[['CD_CVM', 'Date', 'Return_week', 'event']]\n",
    "    \n",
    "    return final_data\n",
    "\n",
    "# Exemplo de uso com a coluna 'Close'\n",
    "# final_data = pd.read_csv('path_to_final_data.csv')  # Carregar os dados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Close'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\thgcn\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-8a2de5e8eb2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mweek_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_week\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-53-a540b9e64a6d>\u001b[0m in \u001b[0;36mreturn_week\u001b[1;34m(final_data)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;31m# Calcular o retorno semanal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mfinal_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Return_week'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Close'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfinal_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Selecionar as colunas relevantes para o DataFrame final\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thgcn\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    871\u001b[0m                     \u001b[1;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 873\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    874\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thgcn\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thgcn\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    808\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0msection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[1;31m# This is an elided recursive call to iloc/loc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"not applicable\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thgcn\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thgcn\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thgcn\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1057\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m         \u001b[1;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1059\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thgcn\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3489\u001b[0m             \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3491\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3493\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thgcn\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Close'"
     ]
    }
   ],
   "source": [
    "week_data = return_week(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando arquivo final na pasta data\n",
    "final_data.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
