{"cells":[{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":465,"status":"ok","timestamp":1723314921696,"user":{"displayName":"David Costa Pereira","userId":"10069676205596512627"},"user_tz":180},"id":"uep96yWDqBq1"},"outputs":[],"source":["import yfinance as yf\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import requests\n","from transformers import AutoTokenizer, BertForSequenceClassification\n","import torch\n","import PyPDF2\n","import json\n","import shutil"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'pwd' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-17-684b4edbec88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#c:\\\\Users\\\\thgcn\\\\OneDrive\\\\Academico\\\\Financial-Reports-Impact\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpwd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;31mNameError\u001b[0m: name 'pwd' is not defined"]}],"source":["#c:\\\\Users\\\\thgcn\\\\OneDrive\\\\Academico\\\\Financial-Reports-Impact\n","pwd"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1723314922889,"user":{"displayName":"David Costa Pereira","userId":"10069676205596512627"},"user_tz":180},"id":"1So0ez1UiLja","outputId":"45607dcb-829b-407d-9b6f-d5c0235f8a99"},"outputs":[{"name":"stdout","output_type":"stream","text":["Pasta 'dataset' foi criada.\n","Pasta 'dataset/prices' foi criada.\n","Pasta 'dataset/prices_processed' foi criada.\n"]}],"source":["folders = [\"dataset\", \"dataset/prices\", \"dataset/prices_processed\"]\n","\n","# Verifica se as pastas existem, se não, cria-as\n","for folder in folders:\n","    if not os.path.exists(folder):\n","        os.makedirs(folder)\n","        print(f\"Pasta '{folder}' foi criada.\")\n","    else:\n","        print(f\"Pasta '{folder}' já existe.\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":690,"status":"ok","timestamp":1723314924948,"user":{"displayName":"David Costa Pereira","userId":"10069676205596512627"},"user_tz":180},"id":"eHjgdyxtqEgX","outputId":"4ccfbc1a-4d94-4853-e0ee-9e1447104174"},"outputs":[{"name":"stderr","output_type":"stream","text":["[*********************100%%**********************]  1 of 1 completed\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Adj Close</th>\n","      <th>Volume</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2013-10-28</th>\n","      <td>6.500000</td>\n","      <td>6.500000</td>\n","      <td>6.353333</td>\n","      <td>6.403333</td>\n","      <td>5.971816</td>\n","      <td>12658800</td>\n","    </tr>\n","    <tr>\n","      <th>2013-10-29</th>\n","      <td>6.400000</td>\n","      <td>6.416666</td>\n","      <td>6.283333</td>\n","      <td>6.310000</td>\n","      <td>5.884773</td>\n","      <td>1794300</td>\n","    </tr>\n","    <tr>\n","      <th>2013-10-30</th>\n","      <td>6.266666</td>\n","      <td>6.266666</td>\n","      <td>6.170000</td>\n","      <td>6.170000</td>\n","      <td>5.754207</td>\n","      <td>1532100</td>\n","    </tr>\n","    <tr>\n","      <th>2013-10-31</th>\n","      <td>6.116666</td>\n","      <td>6.436666</td>\n","      <td>6.116666</td>\n","      <td>6.393333</td>\n","      <td>5.962490</td>\n","      <td>2972700</td>\n","    </tr>\n","    <tr>\n","      <th>2013-11-01</th>\n","      <td>6.323333</td>\n","      <td>6.656666</td>\n","      <td>6.296666</td>\n","      <td>6.633333</td>\n","      <td>6.186317</td>\n","      <td>539700</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2022-12-23</th>\n","      <td>3.990000</td>\n","      <td>4.190000</td>\n","      <td>3.920000</td>\n","      <td>4.180000</td>\n","      <td>4.180000</td>\n","      <td>4693300</td>\n","    </tr>\n","    <tr>\n","      <th>2022-12-26</th>\n","      <td>4.170000</td>\n","      <td>4.260000</td>\n","      <td>4.060000</td>\n","      <td>4.160000</td>\n","      <td>4.160000</td>\n","      <td>1076000</td>\n","    </tr>\n","    <tr>\n","      <th>2022-12-27</th>\n","      <td>4.170000</td>\n","      <td>4.230000</td>\n","      <td>3.830000</td>\n","      <td>3.850000</td>\n","      <td>3.850000</td>\n","      <td>4134200</td>\n","    </tr>\n","    <tr>\n","      <th>2022-12-28</th>\n","      <td>3.880000</td>\n","      <td>4.110000</td>\n","      <td>3.820000</td>\n","      <td>4.110000</td>\n","      <td>4.110000</td>\n","      <td>5200300</td>\n","    </tr>\n","    <tr>\n","      <th>2022-12-29</th>\n","      <td>4.120000</td>\n","      <td>4.200000</td>\n","      <td>3.810000</td>\n","      <td>3.860000</td>\n","      <td>3.860000</td>\n","      <td>8056900</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2278 rows × 6 columns</p>\n","</div>"],"text/plain":["                Open      High       Low     Close  Adj Close    Volume\n","Date                                                                   \n","2013-10-28  6.500000  6.500000  6.353333  6.403333   5.971816  12658800\n","2013-10-29  6.400000  6.416666  6.283333  6.310000   5.884773   1794300\n","2013-10-30  6.266666  6.266666  6.170000  6.170000   5.754207   1532100\n","2013-10-31  6.116666  6.436666  6.116666  6.393333   5.962490   2972700\n","2013-11-01  6.323333  6.656666  6.296666  6.633333   6.186317    539700\n","...              ...       ...       ...       ...        ...       ...\n","2022-12-23  3.990000  4.190000  3.920000  4.180000   4.180000   4693300\n","2022-12-26  4.170000  4.260000  4.060000  4.160000   4.160000   1076000\n","2022-12-27  4.170000  4.230000  3.830000  3.850000   3.850000   4134200\n","2022-12-28  3.880000  4.110000  3.820000  4.110000   4.110000   5200300\n","2022-12-29  4.120000  4.200000  3.810000  3.860000   3.860000   8056900\n","\n","[2278 rows x 6 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# API YahooFinance para baixar os dados historicos\n","def HistoricalData(ticker, startDate, endDate, path2save = ''):\n","\n","  \"\"\"\n","  ticker: Simbolo ação. Ex: VALE\n","  startDate: Data inicial. Ex: 2010-01-01\n","  endDate: Data final. Ex: 2020-12-31\n","  path2save: Caminho para salvar o dataframe.\n","  \"\"\"\n","  data = yf.download(ticker, start=startDate, end=endDate)\n","  df = pd.DataFrame(data)\n","\n","  if path2save != '':\n","    df.to_csv(path2save)\n","\n","  return df\n","\n","\n","dados = HistoricalData(\"ANIM3.SA\", startDate='2010-01-01', endDate='2023-01-01')\n","dados"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1723314926318,"user":{"displayName":"David Costa Pereira","userId":"10069676205596512627"},"user_tz":180},"id":"_97em83mqMFQ"},"outputs":[],"source":["# Criando ferramenta para adicionar novos campos para o dataframe\n","def catalog_return(row, x, name_return):\n","    if row[name_return] > x * row[f'Cumulative_std_{name_return}']:\n","        return 1\n","    elif row[name_return] < -x * row[f'Cumulative_std_{name_return}']:\n","        return -1\n","    else:\n","        return 0\n","\n","\n","class DataProcessing:\n","    def __init__(self, data):\n","        self.dataframe = data\n","        self.dataframe['Date'] = pd.to_datetime(self.dataframe['Date'])\n","        self.dataframe = self.dataframe.sort_values(by='Date')\n","\n","    def get_by_date_range(self, start_date, end_date):\n","        mask = ((self.dataframe['Date'] >= start_date) & (self.dataframe['Date'] <= end_date))\n","        return self.dataframe.loc[mask]\n","\n","    def get_by_date(self, date):\n","        return self.dataframe.loc[(self.dataframe['Date'] == date)]\n","\n","    def create_return_by_period(self, name_return, period, remove_nan=False):\n","        self.dataframe[f'{name_return}'] = np.log(\n","            self.dataframe['Close'] / self.dataframe['Close'].shift(period))\n","        if remove_nan:\n","            self.dataframe = self.dataframe.dropna()\n","\n","    def create_cumulative_std(self, name_return):\n","        self.dataframe[f'Cumulative_std_{name_return}'] = self.dataframe[name_return].expanding().std()\n","\n","    def create_indicator(self, name_return, factor):\n","        self.dataframe[f'Indicator_{name_return}'] = self.dataframe.apply(lambda row:\n","                                                                          catalog_return(row, factor, name_return),\n","                                                                          axis=1)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":463,"status":"ok","timestamp":1723314928323,"user":{"displayName":"David Costa Pereira","userId":"10069676205596512627"},"user_tz":180},"id":"zPx8N49d9RwF","outputId":"856806de-c58e-405e-bdf8-d03417385c29"},"outputs":[{"name":"stderr","output_type":"stream","text":["[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n"]}],"source":["# Baixar precos de varias empresas\n","empresas = [\"ANIM3.SA\", \"AZUL4.SA\", \"BBAS3.SA\"]\n","for emp in empresas:\n","  HistoricalData(ticker=emp, startDate=\"2010-01-01\", endDate=\"2024-01-01\", path2save=f\"dataset/prices/{emp}.csv\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":884,"status":"ok","timestamp":1723314930878,"user":{"displayName":"David Costa Pereira","userId":"10069676205596512627"},"user_tz":180},"id":"HTfi5b38_Vq3","outputId":"3ee4ff1e-54d0-44f6-a4dc-9ba8e58b176c"},"outputs":[{"name":"stdout","output_type":"stream","text":["File ANIM3.SA.csv created and save in dataset/prices_processed/ANIM3.SA.csv\n","File AZUL4.SA.csv created and save in dataset/prices_processed/AZUL4.SA.csv\n","File BBAS3.SA.csv created and save in dataset/prices_processed/BBAS3.SA.csv\n"]}],"source":["files = os.listdir('dataset/prices')\n","for file in files:\n","    data_processed = DataProcessing(pd.read_csv(f'dataset/prices/{file}'))\n","    data_processed.create_return_by_period(name_return='Daily_Return', period=1, remove_nan=False)\n","    data_processed.create_return_by_period(name_return='Week_Return', period=6, remove_nan=False)\n","    data_processed.create_return_by_period(name_return='Month_Return', period=22, remove_nan=False)\n","    data_processed.create_cumulative_std(name_return='Daily_Return')\n","    data_processed.create_cumulative_std(name_return='Week_Return')\n","    data_processed.create_cumulative_std(name_return='Month_Return')\n","    data_processed.create_indicator(name_return='Daily_Return', factor=0.1)\n","    data_processed.create_indicator(name_return='Week_Return', factor=0.1)\n","    data_processed.create_indicator(name_return='Month_Return', factor=0.1)\n","    data_processed.dataframe.to_csv(f'dataset/prices_processed/{file}', index_label=False)\n","    print(f'File {file} created and save in dataset/prices_processed/{file}')"]},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":true,"executionInfo":{"elapsed":2,"status":"ok","timestamp":1723314932406,"user":{"displayName":"David Costa Pereira","userId":"10069676205596512627"},"user_tz":180},"id":"Q2tpE1IBA9dJ"},"outputs":[],"source":["def EventsDate(ticker, userName=\"aluno.thiago.nunes\", password=\"NLPfinance2%4023\", startDate='01012010', endDate=\"01012024\"):\n","  url = \"https://www.comdinheiro.com.br/Clientes/API/EndPoint001.php\"\n","  querystring = {\"code\":\"import_data\"}\n","  payload = f\"username={userName}&password={password}&URL=HistoricoIndicadoresFundamentalistas001.php%3F%26data_ini%3D{startDate}%26data_fim%3D{endDate}%26trailing%3D12%26conv%3DMIXED%26moeda%3DMOEDA_ORIGINAL%26c_c%3Dconsolidado%26m_m%3D1000000%26n_c%3D5%26f_v%3D1%26papel%3D{ticker}%26indic%3DNOME_EMPRESA%2BRL%2BLL%2BEBITDA%2BDATA_PUBLICACAO%2BPRECO_ABERTURA%2BPRECO_FECHAMENTO%26periodicidade%3Dtri%26graf_tab%3Dtabela%26desloc_data_analise%3D1%26flag_transpor%3D0%26c_d%3Dd%26enviar_email%3D0%26enviar_email_log%3D0%26cabecalho_excel%3Dmodo1%26relat_alias_automatico%3Dcmd_alias_01&format=json3\"\n","  headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n","  response = requests.request(\"POST\", url, data=payload, headers=headers, params=querystring)\n","  data = json.loads(response.text)\n","  df = pd.DataFrame(data[\"tables\"][\"tab0\"]).T\n","  novas_colunas = [\"Data\", \"Empresa\", \"Receita\", \"Lucro\", \"EBITDA\", \"Data_Publicacao\", \"Preco_Abertura\", \"Preco_fechamento\", \"Consolidado\", \"Convencao\", \"Moeda\", \"Data_Demonstracao\", \"Meses\", \"Data_Analise\"]\n","  df.columns = novas_colunas\n","  df = df.drop(\"lin0\")\n","  df['Data_Publicacao'] = pd.to_datetime(df['Data_Publicacao'], errors = 'coerce')\n","  df.reset_index(drop=True, inplace=True)\n","  df['Data_Publicacao'] = pd.to_datetime(df['Data_Publicacao'], format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n","  return df\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2995,"status":"ok","timestamp":1723314936506,"user":{"displayName":"David Costa Pereira","userId":"10069676205596512627"},"user_tz":180},"id":"DYrHaVrZCy3G","outputId":"127787ee-2cf4-4aa7-c9cf-30652af88e5f"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-9-6b9ce9254cfd>:12: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n","  df['Data_Publicacao'] = pd.to_datetime(df['Data_Publicacao'], errors = 'coerce')\n"]}],"source":["files = os.listdir('dataset/prices_processed')\n","for emp in files:\n","  price_p = pd.read_csv(f\"dataset/prices_processed/{emp}\")\n","  date_df = EventsDate(ticker= emp[0:-7])\n","  price_p.insert(1, 'event', price_p['Date'].apply(lambda date: 1 if date in date_df['Data_Publicacao'].values else 0))\n","  price_p.to_csv(f\"dataset/prices_processed/{emp}\", index=False)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":311,"status":"ok","timestamp":1723314938175,"user":{"displayName":"David Costa Pereira","userId":"10069676205596512627"},"user_tz":180},"id":"y4CQ0Anuhz1I"},"outputs":[],"source":["df_processed = pd.read_csv(\"dataset/prices_processed/AZUL4.SA.csv\")"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":877,"status":"ok","timestamp":1723314940724,"user":{"displayName":"David Costa Pereira","userId":"10069676205596512627"},"user_tz":180},"id":"tNnVI9scDHKe"},"outputs":[],"source":["def separate_returns(final_data):\n","    # Inicializar colunas se não existirem\n","    if 'return_daily' not in final_data.columns:\n","        final_data['return_daily'] = np.nan\n","    if 'return_week' not in final_data.columns:\n","        final_data['return_week'] = np.nan\n","    if 'return_month' not in final_data.columns:\n","        final_data['return_month'] = np.nan\n","\n","    first_return_daily_list = []\n","    remaining_return_daily_list = []\n","    first_return_week_list = []\n","    remaining_return_week_list = []\n","    first_return_month_list = []\n","    remaining_return_month_list = []\n","\n","    start_idx = 0\n","\n","    while start_idx < len(final_data):\n","        # Encontra o evento\n","        if 1 in final_data[start_idx:]['event'].values:\n","            event_idx = final_data[start_idx:]['event'].eq(1).idxmax()\n","        else:\n","            break\n","        # Encontrar o próximo evento\n","        if 1 in final_data[event_idx+1:]['event'].values:\n","            prox_event_idx = final_data[event_idx+1:]['event'].eq(1).idxmax()\n","        else:\n","            prox_event_idx = len(final_data)\n","\n","        # Calcular o primeiro retorno diario logo após o evento\n","        if event_idx + 1 < len(final_data):\n","            final_data.loc[event_idx + 1, 'return_daily'] = np.log(final_data.loc[event_idx + 1, 'Close'] / final_data.loc[event_idx, 'Close'])\n","            first_return_daily_list.append(final_data.iloc[event_idx + 1])\n","\n","        # Calcular os retornos diarios restantes até o próximo evento\n","        for i in range(event_idx + 2, prox_event_idx, 1):\n","            final_data.loc[i, 'return_daily'] = np.log(final_data.loc[i, 'Close'] / final_data.loc[i-1, 'Close'])\n","            remaining_return_daily_list.append(final_data.iloc[i])\n","\n","        # Calcular o primeiro retorno semanal logo após o evento\n","        if event_idx + 5 < len(final_data):\n","            final_data.loc[event_idx + 5, 'return_week'] = np.log(final_data.loc[event_idx + 5, 'Close'] / final_data.loc[event_idx, 'Close'])\n","            first_return_week_list.append(final_data.iloc[event_idx + 5])\n","\n","        # Calcular os retornos semanais restantes até o próximo evento\n","        for i in range(event_idx + 10, prox_event_idx, 5):\n","            final_data.loc[i, 'return_week'] = np.log(final_data.loc[i, 'Close'] / final_data.loc[i-5, 'Close'])\n","            remaining_return_week_list.append(final_data.iloc[i])\n","\n","\n","        # Calcular o primeiro retorno mensal logo após o evento\n","        if event_idx + 21 < len(final_data):\n","            final_data.loc[event_idx + 21, 'return_month'] = np.log(final_data.loc[event_idx + 21, 'Close'] / final_data.loc[event_idx, 'Close'])\n","            first_return_month_list.append(final_data.iloc[event_idx + 21])\n","\n","        # Calcular os retornos mensais restantes até o próximo evento\n","        for i in range(event_idx + 42, prox_event_idx, 22):\n","            final_data.loc[i, 'return_month'] = np.log(final_data.loc[i, 'Close'] / final_data.loc[i-21, 'Close'])\n","            remaining_return_month_list.append(final_data.iloc[i])\n","\n","        # Reinicia após o evento\n","        start_idx = event_idx + 1\n","\n","    # Criar DataFrames para o primeiro e os demais retornos semanais e mensais\n","    first_return_daily_df = pd.DataFrame(first_return_daily_list).reset_index()[['index',\n","    'Close', 'Date'\n",", 'event', 'return_daily']]\n","    remaining_return_daily_df = pd.DataFrame(remaining_return_daily_list).reset_index()[['index',\n"," 'Close', 'Date'\n",", 'event', 'return_daily']]\n","    first_return_week_df = pd.DataFrame(first_return_week_list).reset_index()[['index',\n"," 'Close', 'Date'\n",", 'event', 'return_week']]\n","    remaining_return_week_df = pd.DataFrame(remaining_return_week_list).reset_index()[['index',\n"," 'Close', 'Date'\n",", 'event', 'return_week']]\n","    first_return_month_df = pd.DataFrame(first_return_month_list).reset_index()[['index',\n"," 'Close', 'Date'\n",", 'event', 'return_month']]\n","    remaining_return_month_df = pd.DataFrame(remaining_return_month_list).reset_index()[['index',\n"," 'Close', 'Date'\n",", 'event', 'return_month']]\n","\n","    first_return_daily_df.rename(columns={'return_daily': 'return'}, inplace=True)\n","    remaining_return_daily_df.rename(columns={'return_daily': 'return'}, inplace=True)\n","    first_return_week_df.rename(columns={'return_week': 'return'}, inplace=True)\n","    remaining_return_week_df.rename(columns={'return_week': 'return'}, inplace=True)\n","    first_return_month_df.rename(columns={'return_month': 'return'}, inplace=True)\n","    remaining_return_month_df.rename(columns={'return_month': 'return'}, inplace=True)\n","\n","    return first_return_daily_df, remaining_return_daily_df, first_return_week_df, remaining_return_week_df, first_return_month_df, remaining_return_month_df\n","\n","\n","first_return_daily_df, remaining_return_daily_df, first_return_week_df, remaining_return_week_df, first_return_month_df, remaining_return_month_df = separate_returns(df_processed)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vJhXP0cjgAM7"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMM5TOISiStHV9eGXoBGAaz","mount_file_id":"1-4AQ2WIu27mJOIf-VkG3M0uIDqtnGJUv","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
